
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Machine Learning &#8212; Data Science Interview Prep</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="SQL &amp; Databases" href="SQL.html" />
    <link rel="prev" title="Probability &amp; Statistics" href="probability.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/dog_computer.webp" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science Interview Prep</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Interview Prep
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Practice Questions
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="probability.html">
   Probability &amp; Statistics
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="SQL.html">
   SQL &amp; Databases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="coding.html">
   Coding &amp; Algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="behavioral.html">
   Behavioral
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../resources.html">
   Resources
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/amichaelsen/data-science-interview-prep"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/amichaelsen/data-science-interview-prep/issues/new?title=Issue%20on%20page%20%2Fpractice/machine_learning.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/amichaelsen/data-science-interview-prep/edit/main/practice/machine_learning.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/practice/machine_learning.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#warm-ups">
   Warm-Ups
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-eigenvectors-and-eigenvalues-what-are-some-properties-of-these">
     What are eigenvectors and eigenvalues? What are some properties of these?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-an-eigendecomposition-what-is-singular-value-decomposition-svd-how-do-they-relate">
     What is an eigendecomposition? What is singular value decomposition (SVD)? How do they relate?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-bias-of-a-model-what-is-its-variance-todo">
     What is the bias of a model? What is its variance? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-overfitting-and-underfitting-how-do-they-relate-to-bias-and-variance">
     What are overfitting and underfitting? How do they relate to bias and variance?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explain-gradient-descent">
     Explain gradient descent.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-regularization-what-are-some-examples-todo">
     What is regularization? What are some examples? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-a-training-validation-split-why-do-we-use-them">
     What is a training/validation split? Why do we use them?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-k-fold-cross-validation-what-about-leave-one-out-loo-cross-validation">
     What is k-fold cross validation? What about leave-one-out (LOO) cross validation?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-bootstrapping-what-is-bagging-todo">
     What is bootstrapping? What is bagging? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#for-each-of-the-following-models-explain-them-and-mention-their-assumptions-and-hyperparameters-linear-regression-logistic-regression-ridge-and-lasso-regression-hard-and-soft-margin-svm-decision-trees-random-forests-naive-bayes-k-nearest-neighbor-todo">
     For each of the following models, explain them and mention their assumptions and hyperparameters: linear regression, logistic regression, RIDGE and LASSO regression, hard and soft margin SVM, decision trees, random forests, naive Bayes, k-nearest neighbor. TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-principal-component-analysis-pca-what-are-its-uses-todo">
     What is Principal Component Analysis (PCA). What are its uses? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-difference-between-supervised-and-unsupervised-learning-give-some-examples-of-each-todo">
     What is the difference between supervised and unsupervised learning? Give some examples of each.  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-precision-and-recall-how-do-they-relate-to-an-f-1-score">
     Define precision and recall. How do they relate to an
     <span class="math notranslate nohighlight">
      \(F_1\)
     </span>
     score?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-sigmoid-function-what-are-some-properties-it-has-todo">
     What is the sigmoid function? What are some properties it has? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-entropy-what-is-gini-impurity-todo">
     What is entropy? What is Gini impurity? TODO
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ml-questions">
   ML Questions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explain-batch-vs-stochastic-gradient-descent-what-are-the-trade-offs-todo">
     Explain batch vs stochastic gradient descent. What are the trade-offs? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-do-we-create-train-val-test-splits-todo">
     Why do we create train/val/test splits?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explain-the-bias-variance-tradeoff-use-an-equation-and-explain-to-non-technical-audiences-todo">
     Explain the Bias-Variance tradeoff. Use an equation and explain to non-technical audiences.  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explain-random-forests-what-are-their-tradeoffs-compared-to-decision-trees-todo">
     Explain random forests. What are their tradeoffs compared to decision trees?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#you-have-trained-a-logistic-classification-model-and-are-asked-to-explain-the-reason-for-the-classification-of-a-particular-data-point-how-would-you-use-the-model-weights-how-would-you-explain-it-without-using-the-model-weights-todo">
     You have trained a logistic classification model and are asked to explain the reason for the classification of a particular data point. How would you use the model weights? How would you explain it without using the model weights?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#you-are-training-a-binary-classification-model-to-detect-a-rare-disease-why-might-you-not-want-to-use-model-accuracy-to-evaluate-the-model-what-might-you-use-instead-todo">
     You are training a binary classification model to detect a rare disease. Why might you not want to use model accuracy to evaluate the model? What might you use instead?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#for-a-binary-classification-problem-we-could-use-linear-regression-to-predict-y-0-1-why-don-t-we-todo">
     For a binary classification problem we could use linear regression to predict
     <span class="math notranslate nohighlight">
      \(y=0,1\)
     </span>
     , why don’t we?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-difference-between-a-generative-and-discriminative-model-give-an-example-of-each-todo">
     What is the difference between a generative and discriminative model? Give an example of each.  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-you-handle-missing-or-corrupted-data-todo">
     How do you handle missing or corrupted data?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-does-pruning-for-decision-trees-work-why-do-we-do-it-what-are-other-methods-to-accomplish-this-and-why-might-we-prefer-pruning-todo">
     How does pruning for decision trees work? Why do we do it? What are other methods to accomplish this, and why might we prefer pruning?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-is-k-nearest-neighbors-different-from-k-means-clustering-todo">
     How is k-Nearest Neighbors different from k-means clustering?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explain-how-roc-curves-work-todo">
     Explain how ROC curves work.  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-type-of-cross-validation-would-you-use-on-time-series-data-todo">
     What type of cross validation would you use on time series data?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-kernel-trick-why-is-it-useful-todo">
     What is the Kernel Trick? Why is it useful?  TODO
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Machine Learning</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#warm-ups">
   Warm-Ups
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-eigenvectors-and-eigenvalues-what-are-some-properties-of-these">
     What are eigenvectors and eigenvalues? What are some properties of these?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-an-eigendecomposition-what-is-singular-value-decomposition-svd-how-do-they-relate">
     What is an eigendecomposition? What is singular value decomposition (SVD)? How do they relate?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-bias-of-a-model-what-is-its-variance-todo">
     What is the bias of a model? What is its variance? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-overfitting-and-underfitting-how-do-they-relate-to-bias-and-variance">
     What are overfitting and underfitting? How do they relate to bias and variance?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explain-gradient-descent">
     Explain gradient descent.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-regularization-what-are-some-examples-todo">
     What is regularization? What are some examples? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-a-training-validation-split-why-do-we-use-them">
     What is a training/validation split? Why do we use them?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-k-fold-cross-validation-what-about-leave-one-out-loo-cross-validation">
     What is k-fold cross validation? What about leave-one-out (LOO) cross validation?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-bootstrapping-what-is-bagging-todo">
     What is bootstrapping? What is bagging? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#for-each-of-the-following-models-explain-them-and-mention-their-assumptions-and-hyperparameters-linear-regression-logistic-regression-ridge-and-lasso-regression-hard-and-soft-margin-svm-decision-trees-random-forests-naive-bayes-k-nearest-neighbor-todo">
     For each of the following models, explain them and mention their assumptions and hyperparameters: linear regression, logistic regression, RIDGE and LASSO regression, hard and soft margin SVM, decision trees, random forests, naive Bayes, k-nearest neighbor. TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-principal-component-analysis-pca-what-are-its-uses-todo">
     What is Principal Component Analysis (PCA). What are its uses? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-difference-between-supervised-and-unsupervised-learning-give-some-examples-of-each-todo">
     What is the difference between supervised and unsupervised learning? Give some examples of each.  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-precision-and-recall-how-do-they-relate-to-an-f-1-score">
     Define precision and recall. How do they relate to an
     <span class="math notranslate nohighlight">
      \(F_1\)
     </span>
     score?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-sigmoid-function-what-are-some-properties-it-has-todo">
     What is the sigmoid function? What are some properties it has? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-entropy-what-is-gini-impurity-todo">
     What is entropy? What is Gini impurity? TODO
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ml-questions">
   ML Questions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explain-batch-vs-stochastic-gradient-descent-what-are-the-trade-offs-todo">
     Explain batch vs stochastic gradient descent. What are the trade-offs? TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-do-we-create-train-val-test-splits-todo">
     Why do we create train/val/test splits?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explain-the-bias-variance-tradeoff-use-an-equation-and-explain-to-non-technical-audiences-todo">
     Explain the Bias-Variance tradeoff. Use an equation and explain to non-technical audiences.  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explain-random-forests-what-are-their-tradeoffs-compared-to-decision-trees-todo">
     Explain random forests. What are their tradeoffs compared to decision trees?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#you-have-trained-a-logistic-classification-model-and-are-asked-to-explain-the-reason-for-the-classification-of-a-particular-data-point-how-would-you-use-the-model-weights-how-would-you-explain-it-without-using-the-model-weights-todo">
     You have trained a logistic classification model and are asked to explain the reason for the classification of a particular data point. How would you use the model weights? How would you explain it without using the model weights?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#you-are-training-a-binary-classification-model-to-detect-a-rare-disease-why-might-you-not-want-to-use-model-accuracy-to-evaluate-the-model-what-might-you-use-instead-todo">
     You are training a binary classification model to detect a rare disease. Why might you not want to use model accuracy to evaluate the model? What might you use instead?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#for-a-binary-classification-problem-we-could-use-linear-regression-to-predict-y-0-1-why-don-t-we-todo">
     For a binary classification problem we could use linear regression to predict
     <span class="math notranslate nohighlight">
      \(y=0,1\)
     </span>
     , why don’t we?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-difference-between-a-generative-and-discriminative-model-give-an-example-of-each-todo">
     What is the difference between a generative and discriminative model? Give an example of each.  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-you-handle-missing-or-corrupted-data-todo">
     How do you handle missing or corrupted data?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-does-pruning-for-decision-trees-work-why-do-we-do-it-what-are-other-methods-to-accomplish-this-and-why-might-we-prefer-pruning-todo">
     How does pruning for decision trees work? Why do we do it? What are other methods to accomplish this, and why might we prefer pruning?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-is-k-nearest-neighbors-different-from-k-means-clustering-todo">
     How is k-Nearest Neighbors different from k-means clustering?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explain-how-roc-curves-work-todo">
     Explain how ROC curves work.  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-type-of-cross-validation-would-you-use-on-time-series-data-todo">
     What type of cross validation would you use on time series data?  TODO
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-kernel-trick-why-is-it-useful-todo">
     What is the Kernel Trick? Why is it useful?  TODO
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="machine-learning">
<h1>Machine Learning<a class="headerlink" href="#machine-learning" title="Permalink to this headline">#</a></h1>
<p>Clicking on a question in the list below will take you to the solution, clicking on the question header will bring you back to this list of questions.</p>
<p><strong>Contributing</strong> Have ideas for more questions? See the <a class="reference internal" href="../intro.html#contributing-label"><span class="std std-ref">contributing section</span></a>.</p>
<p><span style="font-size:2em;">Questions</span></p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#warm-ups" id="id1">Warm-Ups</a></p>
<ul>
<li><p><a class="reference internal" href="#what-are-eigenvectors-and-eigenvalues-what-are-some-properties-of-these" id="id2">What are eigenvectors and eigenvalues? What are some properties of these?</a></p></li>
<li><p><a class="reference internal" href="#what-is-an-eigendecomposition-what-is-singular-value-decomposition-svd-how-do-they-relate" id="id3">What is an eigendecomposition? What is singular value decomposition (SVD)? How do they relate?</a></p></li>
<li><p><a class="reference internal" href="#what-is-the-bias-of-a-model-what-is-its-variance-todo" id="id4">What is the bias of a model? What is its variance? TODO</a></p></li>
<li><p><a class="reference internal" href="#what-are-overfitting-and-underfitting-how-do-they-relate-to-bias-and-variance" id="id5">What are overfitting and underfitting? How do they relate to bias and variance?</a></p></li>
<li><p><a class="reference internal" href="#explain-gradient-descent" id="id6">Explain gradient descent.</a></p></li>
<li><p><a class="reference internal" href="#what-is-regularization-what-are-some-examples-todo" id="id7">What is regularization? What are some examples? TODO</a></p></li>
<li><p><a class="reference internal" href="#what-is-a-training-validation-split-why-do-we-use-them" id="id8">What is a training/validation split? Why do we use them?</a></p></li>
<li><p><a class="reference internal" href="#what-is-k-fold-cross-validation-what-about-leave-one-out-loo-cross-validation" id="id9">What is k-fold cross validation? What about leave-one-out (LOO) cross validation?</a></p></li>
<li><p><a class="reference internal" href="#what-is-bootstrapping-what-is-bagging-todo" id="id10">What is bootstrapping? What is bagging? TODO</a></p></li>
<li><p><a class="reference internal" href="#for-each-of-the-following-models-explain-them-and-mention-their-assumptions-and-hyperparameters-linear-regression-logistic-regression-ridge-and-lasso-regression-hard-and-soft-margin-svm-decision-trees-random-forests-naive-bayes-k-nearest-neighbor-todo" id="id11">For each of the following models, explain them and mention their assumptions and hyperparameters: linear regression, logistic regression, RIDGE and LASSO regression, hard and soft margin SVM, decision trees, random forests, naive Bayes, k-nearest neighbor. TODO</a></p></li>
<li><p><a class="reference internal" href="#what-is-principal-component-analysis-pca-what-are-its-uses-todo" id="id12">What is Principal Component Analysis (PCA). What are its uses? TODO</a></p></li>
<li><p><a class="reference internal" href="#what-is-the-difference-between-supervised-and-unsupervised-learning-give-some-examples-of-each-todo" id="id13">What is the difference between supervised and unsupervised learning? Give some examples of each.  TODO</a></p></li>
<li><p><a class="reference internal" href="#define-precision-and-recall-how-do-they-relate-to-an-f-1-score" id="id14">Define precision and recall. How do they relate to an <span class="math notranslate nohighlight">\(F_1\)</span> score?</a></p></li>
<li><p><a class="reference internal" href="#what-is-the-sigmoid-function-what-are-some-properties-it-has-todo" id="id15">What is the sigmoid function? What are some properties it has? TODO</a></p></li>
<li><p><a class="reference internal" href="#what-is-entropy-what-is-gini-impurity-todo" id="id16">What is entropy? What is Gini impurity? TODO</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#ml-questions" id="id17">ML Questions</a></p>
<ul>
<li><p><a class="reference internal" href="#explain-batch-vs-stochastic-gradient-descent-what-are-the-trade-offs-todo" id="id18">Explain batch vs stochastic gradient descent. What are the trade-offs? TODO</a></p></li>
<li><p><a class="reference internal" href="#why-do-we-create-train-val-test-splits-todo" id="id19">Why do we create train/val/test splits?  TODO</a></p></li>
<li><p><a class="reference internal" href="#explain-the-bias-variance-tradeoff-use-an-equation-and-explain-to-non-technical-audiences-todo" id="id20">Explain the Bias-Variance tradeoff. Use an equation and explain to non-technical audiences.  TODO</a></p></li>
<li><p><a class="reference internal" href="#explain-random-forests-what-are-their-tradeoffs-compared-to-decision-trees-todo" id="id21">Explain random forests. What are their tradeoffs compared to decision trees?  TODO</a></p></li>
<li><p><a class="reference internal" href="#you-have-trained-a-logistic-classification-model-and-are-asked-to-explain-the-reason-for-the-classification-of-a-particular-data-point-how-would-you-use-the-model-weights-how-would-you-explain-it-without-using-the-model-weights-todo" id="id22">You have trained a logistic classification model and are asked to explain the reason for the classification of a particular data point. How would you use the model weights? How would you explain it without using the model weights?  TODO</a></p></li>
<li><p><a class="reference internal" href="#you-are-training-a-binary-classification-model-to-detect-a-rare-disease-why-might-you-not-want-to-use-model-accuracy-to-evaluate-the-model-what-might-you-use-instead-todo" id="id23">You are training a binary classification model to detect a rare disease. Why might you not want to use model accuracy to evaluate the model? What might you use instead?  TODO</a></p></li>
<li><p><a class="reference internal" href="#for-a-binary-classification-problem-we-could-use-linear-regression-to-predict-y-0-1-why-don-t-we-todo" id="id24">For a binary classification problem we could use linear regression to predict <span class="math notranslate nohighlight">\(y=0,1\)</span>, why don’t we?  TODO</a></p></li>
<li><p><a class="reference internal" href="#what-is-the-difference-between-a-generative-and-discriminative-model-give-an-example-of-each-todo" id="id25">What is the difference between a generative and discriminative model? Give an example of each.  TODO</a></p></li>
<li><p><a class="reference internal" href="#how-do-you-handle-missing-or-corrupted-data-todo" id="id26">How do you handle missing or corrupted data?  TODO</a></p></li>
<li><p><a class="reference internal" href="#how-does-pruning-for-decision-trees-work-why-do-we-do-it-what-are-other-methods-to-accomplish-this-and-why-might-we-prefer-pruning-todo" id="id27">How does pruning for decision trees work? Why do we do it? What are other methods to accomplish this, and why might we prefer pruning?  TODO</a></p></li>
<li><p><a class="reference internal" href="#how-is-k-nearest-neighbors-different-from-k-means-clustering-todo" id="id28">How is k-Nearest Neighbors different from k-means clustering?  TODO</a></p></li>
<li><p><a class="reference internal" href="#explain-how-roc-curves-work-todo" id="id29">Explain how ROC curves work.  TODO</a></p></li>
<li><p><a class="reference internal" href="#what-type-of-cross-validation-would-you-use-on-time-series-data-todo" id="id30">What type of cross validation would you use on time series data?  TODO</a></p></li>
<li><p><a class="reference internal" href="#what-is-the-kernel-trick-why-is-it-useful-todo" id="id31">What is the Kernel Trick? Why is it useful?  TODO</a></p></li>
</ul>
</li>
</ul>
</div>
<section id="warm-ups">
<h2><a class="toc-backref" href="#id1">Warm-Ups</a><a class="headerlink" href="#warm-ups" title="Permalink to this headline">#</a></h2>
<section id="what-are-eigenvectors-and-eigenvalues-what-are-some-properties-of-these">
<h3><a class="toc-backref" href="#id2">What are eigenvectors and eigenvalues? What are some properties of these?</a><a class="headerlink" href="#what-are-eigenvectors-and-eigenvalues-what-are-some-properties-of-these" title="Permalink to this headline">#</a></h3>
<p>For a matrix <span class="math notranslate nohighlight">\(A\)</span>, an <strong>eigenvector</strong> <span class="math notranslate nohighlight">\(v\)</span> is a nonzero vector such that <span class="math notranslate nohighlight">\(Av = \lambda v\)</span> for some constant <span class="math notranslate nohighlight">\(\lambda\)</span>. The constant <span class="math notranslate nohighlight">\(\lambda\)</span> is the corresponding <strong>eigenvalue</strong>. Note that <span class="math notranslate nohighlight">\(\lambda\)</span> can be zero.</p>
<p>If <span class="math notranslate nohighlight">\(v,\lambda\)</span> is an eigenvector/value pair for a matrix <span class="math notranslate nohighlight">\(A\)</span>, then <span class="math notranslate nohighlight">\(v,\lambda^k\)</span> is an eigenvector/eigenvalue pair for <span class="math notranslate nohighlight">\(A^k\)</span> for all <span class="math notranslate nohighlight">\(k\geq 0\)</span>. If <span class="math notranslate nohighlight">\(A\)</span> is invertible, this also holds for <span class="math notranslate nohighlight">\(k\leq 0\)</span>, so in particular <span class="math notranslate nohighlight">\(v,\tfrac{1}{\lambda}\)</span> is an eigenvector/value pair for <span class="math notranslate nohighlight">\(A^{-1}\)</span>.</p>
</section>
<section id="what-is-an-eigendecomposition-what-is-singular-value-decomposition-svd-how-do-they-relate">
<h3><a class="toc-backref" href="#id3">What is an eigendecomposition? What is singular value decomposition (SVD)? How do they relate?</a><a class="headerlink" href="#what-is-an-eigendecomposition-what-is-singular-value-decomposition-svd-how-do-they-relate" title="Permalink to this headline">#</a></h3>
<p><strong>Spectral Theorem</strong> If <span class="math notranslate nohighlight">\(A\)</span> is a symmetric real matrix, then <span class="math notranslate nohighlight">\(A=Q\Lambda Q^\top\)</span> for some orthogonal matrix <span class="math notranslate nohighlight">\(Q\)</span> (meaning <span class="math notranslate nohighlight">\(Q\)</span> is symmetric and <span class="math notranslate nohighlight">\(Q^\top Q = QQ^\top=I\)</span>) and diagonal matrix <span class="math notranslate nohighlight">\(\Lambda = \text{diag}(\lambda_1,\ldots, \lambda_n)\)</span>. This is the <strong>eigendecomposition</strong>. (this is unique only when all eigenvalues are distinct)</p>
<p><strong>Singular Value Decomposition</strong> Every real matrix <span class="math notranslate nohighlight">\(A\)</span> (<span class="math notranslate nohighlight">\(m\times n\)</span>) has a decomposition <span class="math notranslate nohighlight">\(A=U\Sigma V^\top\)</span> where <span class="math notranslate nohighlight">\(U\in \mathbb{R}^{m\times m}\)</span>, <span class="math notranslate nohighlight">\(V\in \mathbb{R}^{n\times n}\)</span> and <span class="math notranslate nohighlight">\(\Sigma\in \mathbb{R}^{m\times n}\)</span> is diagonal with the singular values of <span class="math notranslate nohighlight">\(A\)</span> along the diagonal. The singular values are the eigenvalues of <span class="math notranslate nohighlight">\(A^\top A\)</span> and <span class="math notranslate nohighlight">\(AA^\top\)</span>.</p>
<p>When <span class="math notranslate nohighlight">\(A\)</span> is symmetric, the eigendecomposition is a valid singular value decomposition. Note, however, that SVD is not unique as we can always reorder vectors or scale <span class="math notranslate nohighlight">\(U,V\)</span>.</p>
</section>
<section id="what-is-the-bias-of-a-model-what-is-its-variance-todo">
<h3><a class="toc-backref" href="#id4">What is the bias of a model? What is its variance? TODO</a><a class="headerlink" href="#what-is-the-bias-of-a-model-what-is-its-variance-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="what-are-overfitting-and-underfitting-how-do-they-relate-to-bias-and-variance">
<h3><a class="toc-backref" href="#id5">What are overfitting and underfitting? How do they relate to bias and variance?</a><a class="headerlink" href="#what-are-overfitting-and-underfitting-how-do-they-relate-to-bias-and-variance" title="Permalink to this headline">#</a></h3>
<p><strong>Overfitting</strong> is when a model learns the randomness of the training set, not just its underlying structure. This leads to <em>high training accuracy</em> and <em>low validation accuracy</em> or poor generalization.</p>
<p><strong>Underfitting</strong> is when a model is not complex enough to learn the relationships in the data. For example, fitting a linear model to a quadratic dataset. This leads to poor performance on both training and validation accuracy.</p>
<p>Underfitting has high bias but lower variance, whereas overfitting tends to have low bias, but high variance.</p>
</section>
<section id="explain-gradient-descent">
<h3><a class="toc-backref" href="#id6">Explain gradient descent.</a><a class="headerlink" href="#explain-gradient-descent" title="Permalink to this headline">#</a></h3>
<p>Often in machine learning we want to optimize by finding a minimum (or maximum) of a given cost function. For example we may train a model and learn the weights that minimize some loss function on the training data. <strong>Gradient descent</strong> is an optimization tool for iteratively finding the minimizing values for a function.</p>
<p>Requirement: the function must be <strong>differentiable</strong>.</p>
<p>Suppose we have a function <span class="math notranslate nohighlight">\(L(x)\)</span> and we want to solve for the <span class="math notranslate nohighlight">\(\hat{x}\)</span> that minimizes <span class="math notranslate nohighlight">\(L\)</span>. We start at some initial point, <span class="math notranslate nohighlight">\(x_0\)</span>. Taking the derivative (or gradient) of <span class="math notranslate nohighlight">\(L\)</span> at <span class="math notranslate nohighlight">\(x_0\)</span> we can then correct <span class="math notranslate nohighlight">\(x_0\)</span> using this derivative and some learning rate <span class="math notranslate nohighlight">\(\varepsilon\)</span> to get <span class="math notranslate nohighlight">\(x_1 = x_0 -\varepsilon \nabla_L(x_0)\)</span>. If we reach a local minima, then this iteration will be stationary, so we repeat this correction until we converge to <span class="math notranslate nohighlight">\(\hat{x}\)</span>.</p>
<p><img alt="gradient descent" src="../_images/gradient_descent.png" /></p>
<p><a class="reference external" href="https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html">Image Source</a></p>
<p>If <span class="math notranslate nohighlight">\(L\)</span> is <strong>not convex</strong> this may be only a local minima, and not the global minima. However if <span class="math notranslate nohighlight">\(L\)</span> is convex, then the local minima will be global minima as well. Caution: If the function asymptotically decreases then the global optima may be at infinity.</p>
</section>
<section id="what-is-regularization-what-are-some-examples-todo">
<h3><a class="toc-backref" href="#id7">What is regularization? What are some examples? TODO</a><a class="headerlink" href="#what-is-regularization-what-are-some-examples-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="what-is-a-training-validation-split-why-do-we-use-them">
<h3><a class="toc-backref" href="#id8">What is a training/validation split? Why do we use them?</a><a class="headerlink" href="#what-is-a-training-validation-split-why-do-we-use-them" title="Permalink to this headline">#</a></h3>
<p>Most models require training on some data to determine optimal weights. In this case, models are fit to perform well on the training data, so their accuracy must be determined on new data that has not been seen before, but that we have labels for so we can measure accuracy. Thus when training and scoring a model, we will split our labeled data into training and validation data, use the former to train the model and the latter to assess how well the model generalizes to new data.</p>
<p>In the case where we want to tune a hyperparameter of a model, which will require training the model and scoring it repeatedly, our choice of hyperparameter will similarly be selected for its performance on the validation set. Thus we need a third set, the test dataset, to evaluate our final model’s accuracy.</p>
<p>As a general principal, the test data should be extracted at the start and set aside. Then it is only used when a model is totally finished to report the generalization accuracy of the model. If further model tuning is done, ideally new testing data would be collected.</p>
</section>
<section id="what-is-k-fold-cross-validation-what-about-leave-one-out-loo-cross-validation">
<h3><a class="toc-backref" href="#id9">What is k-fold cross validation? What about leave-one-out (LOO) cross validation?</a><a class="headerlink" href="#what-is-k-fold-cross-validation-what-about-leave-one-out-loo-cross-validation" title="Permalink to this headline">#</a></h3>
<p><span class="math notranslate nohighlight">\(k\)</span>-fold cross validation is a method of splitting data for training/validation of a model. Given a number <span class="math notranslate nohighlight">\(k\)</span>, we split the data into <span class="math notranslate nohighlight">\(k\)</span> groups (these can be stratified by class or randomly assigned). Then for each of the <span class="math notranslate nohighlight">\(k\)</span> groups, we generate a split where this group is the validation data and the other <span class="math notranslate nohighlight">\(k-1\)</span> groups are combined into the training data. The model is then trained (using the <span class="math notranslate nohighlight">\(k-1\)</span> groups) and scored (using the remaining <span class="math notranslate nohighlight">\(k\)</span>th group) for each split, and the average accuracy is reported. One advantage to this method is that every data point is used as both training and validation over the course of the model evaluation.</p>
<p>Leave-one-out cross validation is a version of <span class="math notranslate nohighlight">\(k\)</span>-fold CV where <span class="math notranslate nohighlight">\(k\)</span> is the size of the dataset, so that the validation group for each split is a single sample.</p>
</section>
<section id="what-is-bootstrapping-what-is-bagging-todo">
<h3><a class="toc-backref" href="#id10">What is bootstrapping? What is bagging? TODO</a><a class="headerlink" href="#what-is-bootstrapping-what-is-bagging-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="for-each-of-the-following-models-explain-them-and-mention-their-assumptions-and-hyperparameters-linear-regression-logistic-regression-ridge-and-lasso-regression-hard-and-soft-margin-svm-decision-trees-random-forests-naive-bayes-k-nearest-neighbor-todo">
<h3><a class="toc-backref" href="#id11">For each of the following models, explain them and mention their assumptions and hyperparameters: linear regression, logistic regression, RIDGE and LASSO regression, hard and soft margin SVM, decision trees, random forests, naive Bayes, k-nearest neighbor. TODO</a><a class="headerlink" href="#for-each-of-the-following-models-explain-them-and-mention-their-assumptions-and-hyperparameters-linear-regression-logistic-regression-ridge-and-lasso-regression-hard-and-soft-margin-svm-decision-trees-random-forests-naive-bayes-k-nearest-neighbor-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="what-is-principal-component-analysis-pca-what-are-its-uses-todo">
<h3><a class="toc-backref" href="#id12">What is Principal Component Analysis (PCA). What are its uses? TODO</a><a class="headerlink" href="#what-is-principal-component-analysis-pca-what-are-its-uses-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="what-is-the-difference-between-supervised-and-unsupervised-learning-give-some-examples-of-each-todo">
<h3><a class="toc-backref" href="#id13">What is the difference between supervised and unsupervised learning? Give some examples of each.  TODO</a><a class="headerlink" href="#what-is-the-difference-between-supervised-and-unsupervised-learning-give-some-examples-of-each-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="define-precision-and-recall-how-do-they-relate-to-an-f-1-score">
<h3><a class="toc-backref" href="#id14">Define precision and recall. How do they relate to an <span class="math notranslate nohighlight">\(F_1\)</span> score?</a><a class="headerlink" href="#define-precision-and-recall-how-do-they-relate-to-an-f-1-score" title="Permalink to this headline">#</a></h3>
<p>Precision, Recall, and their single combined metric <span class="math notranslate nohighlight">\(F_1\)</span> are measures of model accuracy for rare class classification.</p>
<p>Let <span class="math notranslate nohighlight">\(TP/TN\)</span> be True Positives/Negatives, <span class="math notranslate nohighlight">\(FP/FN\)</span> be False Positives/Negatives.</p>
<p><strong>Precision</strong> is the number of positives predicted that are correct, that is <span class="math notranslate nohighlight">\(\frac{TP}{TP+FP}\)</span>.</p>
<p><strong>Recall</strong> is the number of true positives identified as such by the model, i.e. <span class="math notranslate nohighlight">\(\frac{TP}{TP+FN}\)</span>.</p>
<p>For a single combined metric, we have the <span class="math notranslate nohighlight">\(F_1\)</span> score, <span class="math notranslate nohighlight">\(F_1 = \frac{Precision \times Recall}{Precision + Recall}\)</span>.</p>
</section>
<section id="what-is-the-sigmoid-function-what-are-some-properties-it-has-todo">
<h3><a class="toc-backref" href="#id15">What is the sigmoid function? What are some properties it has? TODO</a><a class="headerlink" href="#what-is-the-sigmoid-function-what-are-some-properties-it-has-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="what-is-entropy-what-is-gini-impurity-todo">
<h3><a class="toc-backref" href="#id16">What is entropy? What is Gini impurity? TODO</a><a class="headerlink" href="#what-is-entropy-what-is-gini-impurity-todo" title="Permalink to this headline">#</a></h3>
</section>
</section>
<section id="ml-questions">
<h2><a class="toc-backref" href="#id17">ML Questions</a><a class="headerlink" href="#ml-questions" title="Permalink to this headline">#</a></h2>
<section id="explain-batch-vs-stochastic-gradient-descent-what-are-the-trade-offs-todo">
<h3><a class="toc-backref" href="#id18">Explain batch vs stochastic gradient descent. What are the trade-offs? TODO</a><a class="headerlink" href="#explain-batch-vs-stochastic-gradient-descent-what-are-the-trade-offs-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="why-do-we-create-train-val-test-splits-todo">
<h3><a class="toc-backref" href="#id19">Why do we create train/val/test splits?  TODO</a><a class="headerlink" href="#why-do-we-create-train-val-test-splits-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="explain-the-bias-variance-tradeoff-use-an-equation-and-explain-to-non-technical-audiences-todo">
<h3><a class="toc-backref" href="#id20">Explain the Bias-Variance tradeoff. Use an equation and explain to non-technical audiences.  TODO</a><a class="headerlink" href="#explain-the-bias-variance-tradeoff-use-an-equation-and-explain-to-non-technical-audiences-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="explain-random-forests-what-are-their-tradeoffs-compared-to-decision-trees-todo">
<h3><a class="toc-backref" href="#id21">Explain random forests. What are their tradeoffs compared to decision trees?  TODO</a><a class="headerlink" href="#explain-random-forests-what-are-their-tradeoffs-compared-to-decision-trees-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="you-have-trained-a-logistic-classification-model-and-are-asked-to-explain-the-reason-for-the-classification-of-a-particular-data-point-how-would-you-use-the-model-weights-how-would-you-explain-it-without-using-the-model-weights-todo">
<h3><a class="toc-backref" href="#id22">You have trained a logistic classification model and are asked to explain the reason for the classification of a particular data point. How would you use the model weights? How would you explain it without using the model weights?  TODO</a><a class="headerlink" href="#you-have-trained-a-logistic-classification-model-and-are-asked-to-explain-the-reason-for-the-classification-of-a-particular-data-point-how-would-you-use-the-model-weights-how-would-you-explain-it-without-using-the-model-weights-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="you-are-training-a-binary-classification-model-to-detect-a-rare-disease-why-might-you-not-want-to-use-model-accuracy-to-evaluate-the-model-what-might-you-use-instead-todo">
<h3><a class="toc-backref" href="#id23">You are training a binary classification model to detect a rare disease. Why might you not want to use model accuracy to evaluate the model? What might you use instead?  TODO</a><a class="headerlink" href="#you-are-training-a-binary-classification-model-to-detect-a-rare-disease-why-might-you-not-want-to-use-model-accuracy-to-evaluate-the-model-what-might-you-use-instead-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="for-a-binary-classification-problem-we-could-use-linear-regression-to-predict-y-0-1-why-don-t-we-todo">
<h3><a class="toc-backref" href="#id24">For a binary classification problem we could use linear regression to predict <span class="math notranslate nohighlight">\(y=0,1\)</span>, why don’t we?  TODO</a><a class="headerlink" href="#for-a-binary-classification-problem-we-could-use-linear-regression-to-predict-y-0-1-why-don-t-we-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="what-is-the-difference-between-a-generative-and-discriminative-model-give-an-example-of-each-todo">
<h3><a class="toc-backref" href="#id25">What is the difference between a generative and discriminative model? Give an example of each.  TODO</a><a class="headerlink" href="#what-is-the-difference-between-a-generative-and-discriminative-model-give-an-example-of-each-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="how-do-you-handle-missing-or-corrupted-data-todo">
<h3><a class="toc-backref" href="#id26">How do you handle missing or corrupted data?  TODO</a><a class="headerlink" href="#how-do-you-handle-missing-or-corrupted-data-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="how-does-pruning-for-decision-trees-work-why-do-we-do-it-what-are-other-methods-to-accomplish-this-and-why-might-we-prefer-pruning-todo">
<h3><a class="toc-backref" href="#id27">How does pruning for decision trees work? Why do we do it? What are other methods to accomplish this, and why might we prefer pruning?  TODO</a><a class="headerlink" href="#how-does-pruning-for-decision-trees-work-why-do-we-do-it-what-are-other-methods-to-accomplish-this-and-why-might-we-prefer-pruning-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="how-is-k-nearest-neighbors-different-from-k-means-clustering-todo">
<h3><a class="toc-backref" href="#id28">How is k-Nearest Neighbors different from k-means clustering?  TODO</a><a class="headerlink" href="#how-is-k-nearest-neighbors-different-from-k-means-clustering-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="explain-how-roc-curves-work-todo">
<h3><a class="toc-backref" href="#id29">Explain how ROC curves work.  TODO</a><a class="headerlink" href="#explain-how-roc-curves-work-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="what-type-of-cross-validation-would-you-use-on-time-series-data-todo">
<h3><a class="toc-backref" href="#id30">What type of cross validation would you use on time series data?  TODO</a><a class="headerlink" href="#what-type-of-cross-validation-would-you-use-on-time-series-data-todo" title="Permalink to this headline">#</a></h3>
</section>
<section id="what-is-the-kernel-trick-why-is-it-useful-todo">
<h3><a class="toc-backref" href="#id31">What is the Kernel Trick? Why is it useful?  TODO</a><a class="headerlink" href="#what-is-the-kernel-trick-why-is-it-useful-todo" title="Permalink to this headline">#</a></h3>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./practice"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="probability.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Probability &amp; Statistics</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="SQL.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">SQL &amp; Databases</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Anya Michaelsen<br/>
  
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>